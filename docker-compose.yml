version: '2.2'
services:
  kibana:
    image: docker.elastic.co/kibana/kibana:6.6.2
    container_name: kibana
    volumes:
      - "./kibana.yml:/usr/share/kibana/config/kibana.yml"
    restart: always
    ports:
      - "5601:5601"
    links:
      - elasticsearch
    depends_on:
      - elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:6.6.2
    container_name: elasticsearch
    restart: always
    environment:
      - node.name=elasticsearch
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - "$HOME/esdata:/usr/share/elasticsearch/data"
    ports:
      - "9200:9200"
  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    restart: always
    volumes:
      - "$HOME/kafkaData:/kafka"
    depends_on:
      - zoo1
    links:
      - zoo1
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ADVERTISED_HOST_NAME: SCBPN900881.local
      KAFKA_ADVERTISED_PORT: 9092
      KAFKA_LOG_RETENTION_HOURS: "168"
      KAFKA_LOG_RETENTION_BYTES: "100000000"
      KAFKA_ZOOKEEPER_CONNECT:  zoo1:2181
      KAFKA_CREATE_TOPICS: "scb-log:1:1"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
  zoo1:
    image: elevy/zookeeper:latest
    container_name: zookeeper_1
    restart: always
    environment:
      MYID: 1
      SERVERS: zoo1
    ports:
      - "2181:2181"
  logstash:
    image: docker.elastic.co/logstash/logstash:6.6.2
    container_name: logstash
    volumes:
      - "./logstash-config/:/usr/share/logstash/pipeline"
    restart: always
    ports:
      - "9600:9600"
      - "7777:7777"
    links:
      - elasticsearch:elasticsearch
      - kafka:kafka